{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "DATA_PATH = Path(\"../data\")\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "test_data = pd.read_csv(DATA_PATH / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060641 0.13718\n",
      "51.564 55.773\n",
      "41.768 45.979\n",
      "20.752 29.855\n",
      "0.060641 0.13718\n",
      "25.951 27.818\n",
      "41.394 43.257\n"
     ]
    }
   ],
   "source": [
    "print(train_data['xmeas_39'].min(),train_data['xmeas_39'].max()) 0.06~0.14\n",
    "print(train_data['xmeas_40'].min(),train_data['xmeas_40'].max()) 51~56\n",
    "print(train_data['xmeas_41'].min(),train_data['xmeas_41'].max()) 41~56\n",
    "print(train_data['xmeas_14'].min(),train_data['xmeas_14'].max()) 20~30\n",
    "print(train_data['xmeas_5'].min(),train_data['xmeas_5'].max()) 25~28\n",
    "print(train_data['xmeas_6'].min(),train_data['xmeas_6'].max()) 41~44\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['faultNumber', 'simulationRun', 'sample', 'xmeas_1', 'xmeas_2',\n",
       "       'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8',\n",
       "       'xmeas_9', 'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14',\n",
       "       'xmeas_15', 'xmeas_16', 'xmeas_17', 'xmeas_18', 'xmeas_19', 'xmeas_20',\n",
       "       'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25', 'xmeas_26',\n",
       "       'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32',\n",
       "       'xmeas_33', 'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38',\n",
       "       'xmeas_39', 'xmeas_40', 'xmeas_41', 'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4',\n",
       "       'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', 'xmv_10', 'xmv_11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df) -> pd.DataFrame:\n",
    "    numeric_cols = [\n",
    "       'xmeas_1', 'xmeas_2',\n",
    "       'xmeas_3', 'xmeas_4', 'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8',\n",
    "       'xmeas_9', 'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14',\n",
    "       'xmeas_15', 'xmeas_16', 'xmeas_17', 'xmeas_18', 'xmeas_19', 'xmeas_20',\n",
    "       'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25', 'xmeas_26',\n",
    "       'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_30', 'xmeas_31', 'xmeas_32',\n",
    "       'xmeas_33', 'xmeas_34', 'xmeas_35', 'xmeas_36', 'xmeas_37', 'xmeas_38',\n",
    "       'xmeas_39', 'xmeas_40', 'xmeas_41', 'xmv_1', 'xmv_2', 'xmv_3', 'xmv_4',\n",
    "       'xmv_5', 'xmv_6', 'xmv_7', 'xmv_8', 'xmv_9', 'xmv_10', 'xmv_11'\n",
    "    ]\n",
    "    return df[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = process_data(train_data)\n",
    "test_df = process_data(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridAnomalyDetector:\n",
    "    def __init__(self):\n",
    "        self.iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "        self.sgd_svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_stats = {}  # 범위 기준 저장\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        # 1. 상관계수 계산\n",
    "        corr_matrix = data.corr()\n",
    "        low_corr_features = [col for col in data.columns if corr_matrix[col].abs().max() < 0.3]\n",
    "\n",
    "        # 2. 범위 기반 이상 탐지 기준 저장 (평균 ± 3표준편차)\n",
    "        for feature in low_corr_features:\n",
    "            mean = data[feature].mean()\n",
    "            std = data[feature].std()\n",
    "            self.feature_stats[feature] = (mean, std)\n",
    "\n",
    "        # 3. 범위 기반 피처 제거 후 나머지로 모델 학습\n",
    "        data_for_model = data.drop(columns=low_corr_features)\n",
    "        scaled_data = self.scaler.fit_transform(data_for_model)\n",
    "\n",
    "        # IsolationForest와 SGDOneClassSVM 학습\n",
    "        self.iso_forest.fit(scaled_data)\n",
    "        self.sgd_svm.fit(scaled_data)\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        # 1. 범위 기반 예측 수행\n",
    "        range_outliers = pd.DataFrame(index=data.index)\n",
    "        for feature, (mean, std) in self.feature_stats.items():\n",
    "            lower_bound = mean - 3 * std\n",
    "            upper_bound = mean + 3 * std\n",
    "            range_outliers[feature + '_Outlier'] = (~data[feature].between(lower_bound, upper_bound)).astype(int)\n",
    "\n",
    "        # 2. 나머지 피처에 대해 IsolationForest와 SGDOneClassSVM 적용\n",
    "        data_for_model = data.drop(columns=self.feature_stats.keys(), errors='ignore')\n",
    "        scaled_data = self.scaler.transform(data_for_model)\n",
    "\n",
    "        iso_labels = (self.iso_forest.predict(scaled_data) == -1).astype(int)  # 1: 이상, 0: 정상\n",
    "        svm_labels = (self.sgd_svm.predict(scaled_data) == -1).astype(int)  # 1: 이상, 0: 정상\n",
    "\n",
    "        # 3. 결과 통합 (다수결 방식)\n",
    "        results = pd.DataFrame({\n",
    "            'IsolationForest': iso_labels,\n",
    "            'SGDOneClassSVM': svm_labels\n",
    "        }, index=data.index)\n",
    "\n",
    "        results = pd.concat([results, range_outliers], axis=1)\n",
    "        results['Final_Label'] = (results.mean(axis=1) >= 0.5).astype(int)  # 다수결\n",
    "\n",
    "        return results[['Final_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_data)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 새로운 데이터에 대한 예측\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df\u001b[49m\n\u001b[1;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(new_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 학습 데이터 준비\n",
    "    np.random.seed(42)\n",
    "    train_data = train_df\n",
    "\n",
    "    # 모델 생성 및 학습\n",
    "    model = HybridAnomalyDetector()\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # 새로운 데이터에 대한 예측\n",
    "    new_data = test_df\n",
    "    predictions = model.predict(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('multi.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
